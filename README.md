# GCN_test
>GCN理论+实践

![](./img/%E5%85%AC%E5%BC%8F.jpg)

### GCN模型结构及MLP模型结构(对比看看效果)
```bash
GCN(
  (conv1): GCNConv(34, 4)
  (conv2): GCNConv(4, 4)
  (conv3): GCNConv(4, 2)
  (cls): Linear(in_features=2, out_features=4, bias=True)
)
MLP(
  (lin1): Linear(in_features=34, out_features=4, bias=True)
  (lin2): Linear(in_features=4, out_features=4, bias=True)
)
```
**实验结果**
```bash
GCN.loss:1.432432770729065, GCN.acc:0.25, MLP.loss:1.4449759721755981, MLP.acc:0.25
GCN.loss:1.4260591268539429, GCN.acc:0.25, MLP.loss:1.4378281831741333, MLP.acc:0.25
GCN.loss:1.4194817543029785, GCN.acc:0.25, MLP.loss:1.4010705947875977, MLP.acc:0.25
GCN.loss:1.4125844240188599, GCN.acc:0.25, MLP.loss:1.3778226375579834, MLP.acc:0.25
GCN.loss:1.4053231477737427, GCN.acc:0.25, MLP.loss:1.3977465629577637, MLP.acc:0.25
GCN.loss:1.3977205753326416, GCN.acc:0.25, MLP.loss:1.4000916481018066, MLP.acc:0.25
GCN.loss:1.3898134231567383, GCN.acc:0.25, MLP.loss:1.3849825859069824, MLP.acc:0.25
GCN.loss:1.3816187381744385, GCN.acc:0.25, MLP.loss:1.3526484966278076, MLP.acc:0.25
GCN.loss:1.3731058835983276, GCN.acc:0.25, MLP.loss:1.3954524993896484, MLP.acc:0.25
GCN.loss:1.3641955852508545, GCN.acc:0.25, MLP.loss:1.3735404014587402, MLP.acc:0.25
GCN.loss:1.3547390699386597, GCN.acc:0.25, MLP.loss:1.3750653266906738, MLP.acc:0.25
GCN.loss:1.3445132970809937, GCN.acc:0.25, MLP.loss:1.3404767513275146, MLP.acc:0.5
GCN.loss:1.3332808017730713, GCN.acc:0.25, MLP.loss:1.3703616857528687, MLP.acc:0.25
GCN.loss:1.3208646774291992, GCN.acc:0.25, MLP.loss:1.3736401796340942, MLP.acc:0.25
GCN.loss:1.307186245918274, GCN.acc:0.25, MLP.loss:1.3303556442260742, MLP.acc:0.5
GCN.loss:1.2922799587249756, GCN.acc:0.25, MLP.loss:1.3871992826461792, MLP.acc:0.25
GCN.loss:1.2763046026229858, GCN.acc:0.25, MLP.loss:1.2883919477462769, MLP.acc:0.75
GCN.loss:1.2595293521881104, GCN.acc:0.25, MLP.loss:1.3022565841674805, MLP.acc:0.75
GCN.loss:1.2422494888305664, GCN.acc:0.25, MLP.loss:1.3100287914276123, MLP.acc:0.5
GCN.loss:1.2245826721191406, GCN.acc:0.25, MLP.loss:1.362260341644287, MLP.acc:0.25
GCN.loss:1.206296443939209, GCN.acc:0.5, MLP.loss:1.3257907629013062, MLP.acc:0.5
GCN.loss:1.1869962215423584, GCN.acc:0.5, MLP.loss:1.3755202293395996, MLP.acc:0.25
GCN.loss:1.1664949655532837, GCN.acc:0.5, MLP.loss:1.3874385356903076, MLP.acc:0.25
GCN.loss:1.144914150238037, GCN.acc:0.5, MLP.loss:1.3735827207565308, MLP.acc:0.25
GCN.loss:1.1225954294204712, GCN.acc:0.75, MLP.loss:1.3872199058532715, MLP.acc:0.25
GCN.loss:1.0999597311019897, GCN.acc:1.0, MLP.loss:1.3256040811538696, MLP.acc:0.25
GCN.loss:1.0773210525512695, GCN.acc:1.0, MLP.loss:1.256030559539795, MLP.acc:0.5
GCN.loss:1.0546810626983643, GCN.acc:1.0, MLP.loss:1.2952100038528442, MLP.acc:0.5
GCN.loss:1.0317333936691284, GCN.acc:1.0, MLP.loss:1.2428983449935913, MLP.acc:0.5
GCN.loss:1.0082557201385498, GCN.acc:1.0, MLP.loss:1.387282133102417, MLP.acc:0.0
GCN.loss:0.9844311475753784, GCN.acc:1.0, MLP.loss:1.2403138875961304, MLP.acc:0.75
GCN.loss:0.9607105255126953, GCN.acc:1.0, MLP.loss:1.2102612257003784, MLP.acc:0.5
GCN.loss:0.9374310374259949, GCN.acc:1.0, MLP.loss:1.279502511024475, MLP.acc:0.5
GCN.loss:0.914531409740448, GCN.acc:1.0, MLP.loss:1.2904598712921143, MLP.acc:0.25
GCN.loss:0.8916864395141602, GCN.acc:1.0, MLP.loss:1.1291499137878418, MLP.acc:0.75
GCN.loss:0.8687676191329956, GCN.acc:1.0, MLP.loss:1.1723170280456543, MLP.acc:0.75
GCN.loss:0.8460161089897156, GCN.acc:1.0, MLP.loss:1.1725609302520752, MLP.acc:0.5

......
```